\subsection{Bayesian Generalized Linear Model}\label{sec:logit-glm}

Bayesian generalized linear models extend the familiar Bayesian linear regression framework by replacing the Gaussian distributional assumption on $\by$ with an arbitrary exponential-family distribution \citep{nelder_generalized_1972,west_dynamic_1985}. 
In their most general form, we assume
\begin{equation*}
    \by \mid \btheta \sim F(g^{-1}(\bX \btheta)),
\end{equation*}

where $F$ is any exponential-family distribution (e.g.\@ Binomial, Poisson, Gamma) and $g^{-1}$ is the inverse link function.
Priors for the parameter $\btheta$ can be set in the same way as for the Bayesian linear model. However, in practice, the prior choice also depends on the link function, since the link transforms the linear predictor and thereby influences the prior's effect on the response scale \citep{west_dynamic_1985,hosack_prior_2017}.

\subsection{Bayesian Logistic Model} \label{sec:logit-logit}

We are going to illustrate Bayesian GLMs with the example of logistic regression models, which have a wide variety of applications in statistics, from text classification to medicine and genetic modeling \citep[see e.g.][for interesting applications]{dayanik_constructing_2006,sondhi_bayesian_2021}.

\subsubsection*{Model Definition}

The Bayesian logistic regression model is defined as
\begin{equation}\label{eq:logit}
    \begin{aligned}
        \by_i \mid \btheta &\sim \text{Bin}(1, g^{-1}(\bx_i \btheta)), \quad i = 1, \dots, n \\
        g^{-1}(\bx_i \btheta) &= \sigma(\bx_i \btheta).
    \end{aligned}
\end{equation}

for observations $\bx_i = (1, x_{i1}, \dots, x_{ip})^\top$ and where $\sigma(y) = \frac{\exp(y)}{1 + \exp(y)}$ is the logistic (sigmoid) function.  Other choices like the probit link can also be used \citep[see e.g.][]{albert_bayesian_1993}.

\subsubsection*{Prior Choice}

Unlike the Gaussian linear model, the logistic likelihood breaks conjugacy.
Nevertheless, we can use a Gaussian prior (\autoref{eq:NIGprior}) or an (improper) flat prior (\autoref{eq:flat-prior}) for $\btheta$, but both require approximate inference (see \Cref{sec:logit-inf}).\\

To address separation (i.e.\@ perfect prediction) and to induce shrinkage, heavier-tailed priors are commonly employed.
\citet{gelman_weakly_2008} introduced the t-distribution as a prior for low-information settings and mentions the Cauchy distribution as another possibility, which is elaborated on by \citet{ghosh_use_2017}.\\

\textbf{Regularization} can be achieved using the same prior distributions as introduced for Bayesian linear regression in \Cref{sec:lm-regularization} \citep[see e.g.][]{van_erp_shrinkage_2019,fahrmeir_bayesian_2010,ohara_review_2009}.

\subsection{Approximate Bayesian Inference} \label{sec:logit-inf}

Unlike for the linear model, Bayesian inference with a closed form posterior is not possible in most cases \citep[see e.g.][]{polson_bayesian_2013}.
To sample from the posterior and PPD, we need to use approximate Bayesian inference methods.

\subsubsection*{Sampling from the Posterior with MCMC Methods}

Markov chain Monte Carlo (MCMC) generates samples from the posterior $p(\btheta\mid \by)$ without making any (explicit) assumptions about the form of the posterior, although MCMC performs best if the parameter posterior is known up to a constant.
The Metropolis–Hastings algorithm \citep{hastings_monte_1970} for $K$ samples\footnotemark \; proceeds as follows:
\footnotetext{Note that by construction, the samples are (sometimes heavily) correlated and that the number of repetitions necessary until convergence depends on $\btheta^{(1)}$.}
\begin{enumerate}
    \item Initialize $\btheta^{(1)}$
    \item For $k = 1, \dots, K$
    \begin{enumerate}
        \item Draw $\btheta^{(*)}$ from the \textit{proposal distribution} $q(\btheta^{(*)} \mid \btheta^{(k)})$
        \item calculate the \textit{acceptance probably} 
            \begin{equation*}
                \alpha = \min \Bigl(
                    1, \frac{
                        p(\btheta^{(*)} \mid \by)\; p(\btheta^{(*)}) \; q(\btheta^{(k)} \mid \btheta^{(*)})}{
                            p(\btheta^{(k)} \mid \by)\; p(\btheta^{(k)}) \; q(\btheta^{(*)} \mid \btheta^{(k)})
                        }
                    \Bigr)
            \end{equation*}
        \item Accept or discard the proposal $\btheta^{(*)}$ (for $u \sim \text{Uni}[0, 1]$)
            \begin{equation*}
                \begin{cases}
                    u \le \alpha & \btheta^{(k+1)} = \btheta^{(*)}\\
                    u > \alpha & \btheta^{(k+1)} = \btheta^{(k)}\\
                \end{cases}
            \end{equation*}
    \end{enumerate}
\end{enumerate}

The efficiency of Metropolis-Hastings depends critically on the proposal distribution $q$.
A common choice is a Gaussian distribution centered at the current state with the covariance given by the (estimated) negative inverse Hessian of the log–posterior, often obtained via IWLS \citep{gamerman_markov_1998,lenk_bayesian_2000,scott_data_2011}:\footnotemark
\begin{equation*}
    q(\btheta^{(*)} \mid \btheta^{(k)}) \sim \Ncal(\btheta^{(k)} \mid -H^{-1}(\btheta^{(k)})), \quad H(\btheta) = \nabla_{\btheta}^2  \log \Bigl(p(\btheta^{(k)} \mid \by)\; p(\btheta^{(k)})\Bigr)
\end{equation*}

\citep{scott_data_2011} argues that using heavier-tailed proposals (e.g.\@ Student–$t$) can improve mixing, which means that the algorithm converges faster and a shorter burn-in period is necessary.\\

\footnotetext{
    The symmetry of the Gaussian distribution simplifies the algorithm to the Metropolis algorithm, where the acceptance probability can be calculated only using $p(\btheta \mid \by)\; p(\btheta)$.
}

Beyond Metropolis–Hastings, several advanced samplers are popular:

\begin{itemize}
    \item Gibbs sampling for models with conditional conjugacy \citep{dellaportas_bayesian_1993}.
    \item Hamiltonian Monte Carlo, which exploits gradient information to explore high-dimensional posteriors efficiently \citep{neal_probabilistic_1993}.
    \item Data augmentation \citep{albert_bayesian_1993}, using Gaussian scale mixtures and introducing auxiliary latent variables to restore conjugacy in logistic models \citep{holmes_efficient_nodate,fruhwirth-schnatter_auxiliary_2007,scott_data_2011}.
\end{itemize}

\subsubsection*{Full Bayes with Laplace Approximation}

In contrast to MCMC methods, Laplace approximation (LA) approximates the full posterior with a Gaussian distribution \citep{tierney_accurate_1986}:
\begin{equation*}
    p(\btheta \mid \by) \approx \Ncal(\hbtheta_{MAP}, H^{-1}(\hbtheta_{MAP})),
\end{equation*}

where $\hbtheta_{MAP}$ is the maximum posterior estimate, obtained by maximizing the (real) posterior with standard optimization methods.\\

In the case of the Bayesian logistic model with a simple parameter prior $\btheta \sim \Ncal(\bnull, \ssd \bI)$, this results in
\begin{equation*}
    \begin{aligned}
        \hbtheta_{MAP} &= \arg \max_{\btheta} p(\btheta \mid \by)
            \overset{\text{Bayes' rule}}{=} \arg \max_{\btheta} p(\by \mid \btheta) p(\btheta) \; d\btheta  \\
            &= \arg \max_{\btheta} \sumin \log \Bigl( \sigma(y_i \; \bx_i\btheta)\Bigr) - \frac{1}{2 \ssd} \btheta^\top \btheta \\
        H(\btheta) &= - \nabla^2_{\btheta}  \log p (\btheta \mid \by) = \frac{1}{\ssd} \bI + \sumin
        \sigma(y_i \; \bx_i\btheta) \Bigl(1 - \sigma(y_i \; \bx_i\btheta)\Bigr)
            \bx_i \bx_i^\top.
    \end{aligned}
\end{equation*}

For hierarchical models, \citet{rue_approximate_2009} proposed an extended algorithm based on integrated nested Laplace approximations (INLA).

\subsubsection*{Posterior Predictive Distribution}

In logistic regression, which is a binary classification setting, we obtain the PPD by calculating the distribution of the positive class\footnote{
    Encoded here with $y_i \in \{0 \text{ (negative)}, 1 \text{ (positive)}\}$
} $p(\ty = 1 \mid \btheta, \by)$ and inferring the negative class.\\

As MCMC results in samples from the posterior, we can use the samples $\btheta^{(k)}$ to approximate the PPD with
\begin{equation}\label{eq:ppd-sample}
    p(\ty = 1 \mid \btheta, \by) \approx \frac{1}{K} \sum_{k=1}^{K} \sigma(\tX \btheta^{(k)}).
\end{equation}

Under Laplace approximation, we may either
\begin{itemize}
    \item draw samples $\btheta^{(s)} \sim \Ncal(\hbtheta_{MAP}, H^{-1}(\hbtheta_{MAP}))$ with $s = 1, \dots, S$ and compute \autoref{eq:ppd-sample} or
    \item use the LA-approximated PPD and compute
    \begin{equation*}
        p(\ty = 1 \mid \btheta, \by) = \int \sigma(\tX \btheta) \; \Ncal_{\btheta}(\hbbeta_{MAP}, H^{-1} (\hbbeta_{MAP})) \; d \btheta.
    \end{equation*}
\end{itemize}
