\subsection{Bayesian Generalized Linear Regression Model}\label{sec:logit-glm}

Bayesian generalized linear models extend the familiar Bayesian linear regression framework by replacing the Gaussian distributional assumption on $\by$ with an arbitrary exponential-family distribution \citep{nelder_generalized_1972,west_dynamic_1985}. 
In their most general form, we assume
\begin{equation*}
    \by \mid \btheta \sim F(g^{-1}(\bX \btheta)),
\end{equation*}

where $F$ is any exponential-family distribution (e.g. Binomial, Poisson, Gamma) and $g^{-1}$ is the inverse link function.
Priors for the parameter $\btheta$ can be set in the same way as for the Bayesian linear model. However, in practice, the prior choice also depends on the link function \citep{west_dynamic_1985}.

\subsection{Bayesian Logistic Regression Model} \label{sec:logit-logit}

We are going to illustrate Bayesian GLMs with the example of Logistic regression models, which have a wide variety of applications in statistics, from text classification to medicine and genetic modeling. (SOURCE)

\subsubsection*{Model definition}

The Bayesian logistic regression model is defined as
\begin{equation}\label{eq:logit}
    \begin{aligned}
        \by_i \mid \btheta &\sim \text{Bin}(1, g^{-1}(\bx_i \btheta)), \quad i = 1, \dots, n \\
        g^{-1}(\bx_i \btheta) &= \sigma(\bx_i \btheta).
    \end{aligned}
\end{equation}

where $\sigma(\bx_i \btheta) = \frac{\exp(\bx_i \btheta)}{1 + \exp(\bx_i \btheta)}$ is the logistic (sigmoid) function.  Other choices like the probit link can also be used.

\subsubsection*{Prior choice}

Unlike the Gaussian linear model, the logistic likelihood breaks conjugacy.
Nevertheless, we can use a Gaussian prior (\autoref{eq:NIGprior}) or an (improper) flat prior (\autoref{eq:flat-prior}) for $\btheta$, but both require approximate inference (see \autoref{sec:logit-inf}).\\

To address separation (i.e. perfect prediction) and to induce shrinkage, heavier-tailed priors are commonly employed.
\citet{gelman_weakly_2008} introduced the t-distribution as a prior for low-information settings and mentions the Cauchy distribution as another possibility, which is elaborated on by \Citet{ghosh_use_2017}.\\

\textbf{Regularization} can also be achieved with the same prior distributions as introduced for Bayesian linear regression in \autoref{sec:lm-regularization} \Citep[see e.g.][]{van_erp_shrinkage_2019,fahrmeir_bayesian_2010,ohara_review_2009}.

\subsection{Approximate Bayesian inference} \label{sec:logit-inf}

Unlike for the linear model, Bayesian inference with closed-form posteriors is not possible in most cases.
To sample from the posterior and PPD, we need to use approximate Bayesian inference methods.

\subsubsection*{Sampling from the posterior with MCMC methods}

Markov Chain Monte Carlo (MCMC) generates samples from the posterior $p(\btheta\mid \by)$ without making any (explicit) assumptions about the form of the posterior, although MCMC performs best if the parameter posterior is known up to a constant.
The Metropolis–Hastings algorithm \citep{hastings_monte_1970} for $K$ samples\footnotemark proceeds as follows:
\footnotetext{Note that by construction, the samples are (sometimes heavily) correlated and that the number of repetitions necessary until convergence depends on $\btheta^{(0)}$.}
\begin{enumerate}
    \item Initialize $\btheta^{(1)}$
    \item For $k = 1, \dots, K$
    \begin{enumerate}
        \item Draw $\btheta^{(*)}$ from the \textit{proposal distribution} $q(\btheta^{(*)} \mid \btheta^{(k)})$
        \item calculate the \textit{accceptance probably} 
            \begin{equation*}
                \alpha = \min \Bigl(
                    1, \frac{
                        p(\btheta^{(*)} \mid \by)\; p(\btheta^{(*)}) \; q(\btheta^{(k)} \mid \btheta^{(*)})}{
                            p(\btheta^{(k)} \mid \by)\; p(\btheta^{(k)}) \; q(\btheta^{(*)} \mid \btheta^{(k)})
                        }
                    \Bigr)
            \end{equation*}
        \item Accept or discard the proposal $\btheta^{(*)}$ (for $u \sim \text{Uni}[0, 1]$)
            \begin{equation*}
                \begin{cases}
                    u \le \alpha & \btheta^{(k+1)} = \btheta^{(*)}\\
                    u > \alpha & \btheta^{(k+1)} = \btheta^{(k)}\\
                \end{cases}
            \end{equation*}
    \end{enumerate}
\end{enumerate}

The efficiency of Metropolis-Hastings depends critically on the proposal distribution $q$.
A common choice is a Gaussian centered at the current state with covariance given by the (estimated) negative inverse Hessian of the log–posterior, often obtained via IWLS \citep{gamerman_markov_1998,lenk_bayesian_2000,scott_data_2011}:\footnotemark
\begin{equation*}
    q(\btheta^{(*)} \mid \btheta^{(k)}) \sim \Ncal(\btheta^{(k)} \mid -H^{-1}(\btheta^{(k)})), \quad H(\btheta) = \nabla_{\btheta}^2  \log \Bigl(p(\btheta^{(k)} \mid \by)\; p(\btheta^{(k)})\Bigr)
\end{equation*}

\citep{scott_data_2011} argues that using heavier-tailed proposals (e.g. Student–$t$) can improve mixing by allowing larger moves.\\
\footnotetext{
    The symmetry of the Gaussian distribution simplifies the algorithm to the Metropolis algorithm, where the acceptance probability can be calculated only using $p(\btheta \mid \by)\; p\btheta$.
}

Beyond Metropolis–Hastings, several advanced samplers are popular:

\begin{itemize}
    \item Gibbs sampling for models with conditional conjugacy or augmentation \citep{dellaportas_bayesian_1993}.
    \item Hamiltonian Monte Carlo, which exploits gradient information to explore high‐dimensional posteriors efficiently \citep{neal_probabilistic_1993}.
    \item Data augmentation \citep{albert_bayesian_1993}, using Gaussian scale mixtures and introducing auxiliary latent variables to restore conjugacy in logistic models \citep{holmes_efficient_nodate,fruhwirth-schnatter_auxiliary_2007,scott_data_2011}.
\end{itemize}

\subsubsection*{Full Bayes with Laplace Approximation}

In contrast to MCMC methods, Laplace Approximation (LA) approximates the full posterior distribution by assuming a Gaussian distribution \citep{tierney_accurate_1986}:
\begin{equation*}
    p(\btheta \mid \by) \approx \Ncal(\hbtheta_{MAP}, H^{-1}(\hbtheta_{MAP})),
\end{equation*}

where $\hbtheta_{MAP}$ is the maximum posterior estimate, obtained by maximizing the (real) posterior with standard optimization methods.\\

In the case of the Bayesian logistic model with a simple parameter prior $\btheta \sim \Ncal(\bnull, \ssd \bI)$, this results in
\begin{equation*}
    \begin{aligned}
        \hbtheta_{MAP} &= \arg \max_{\btheta} p(\btheta \mid \by)
            \overset{\text{Bayes' rule}}{=} \arg \max_{\btheta} p(\by \mid \btheta) p(\btheta) \; d\btheta  \\
            &= \arg \max_{\btheta} \sumin \log \Bigl( \sigma(y_i \bx_i\btheta)\Bigr) - \frac{1}{2 \ssd} \btheta^\top \btheta \\
        H(\btheta) &= - \nabla^2_{\btheta}  \log p (\btheta \mid \by) = \frac{1}{\ssd} \bI + \sumin
        \sigma(y_i \bx_i\btheta) \Bigl(1 - \sigma(y_i \bx_i\btheta)\Bigr)
            \bx_i \bx_i^\top.
    \end{aligned}
\end{equation*}

For hierarchical models, \citet{rue_approximate_2009} proposed an extended algorithm based on Integrated Nested Laplace Approximation.

\subsubsection*{Posterior predictive distribution}

In a binary classification setting, we obtain the PPD by calculating the distribution of the positive class\footnote{
    Encoded here with $y_i \in \{0 \text{ (negative)}, 1 \text{ (positive)}\}$
} $p(\ty = 1 \mid \btheta, \by)$ and inferring the negative class.\\

As MCMC results in samples from the posterior, we can use the samples $\btheta_k$ to approximate the PPD with
\begin{equation}\label{eq:ppd-sample}
    p(\ty = 1 \mid \btheta, \by) \approx \frac{1}{K} \sum_{k=1}^{K} \sigma(\tX \btheta_k).
\end{equation}

Under Laplace Approximation, we may either
\begin{itemize}
    \item draw samples $\btheta_s \sim \Ncal(\hbtheta_{MAP}, H^{-1}(\hbtheta_{MAP}))$ with $s = 1, \dots, S$ and compute \autoref{eq:ppd-sample} or
    \item use the LA-approximated PPD and compute
    \begin{equation*}
        p(\ty = 1 \mid \btheta, \by) = \int \sigma(\tX \btheta) \; \Ncal_{\btheta}(\hbbeta_{MAP}, H^{-1} (\hbbeta_{MAP})) \; d \btheta.
    \end{equation*}
\end{itemize}
