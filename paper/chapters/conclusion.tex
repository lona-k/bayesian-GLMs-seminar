In this paper, we reviewed the model specification, prior choice, and approximate inference methods for Bayesian generalized linear models.
We detailed how priors can be used to stabilize estimation and to implement familiar regularization in a Bayesian setting.
Using the example of logistic regression, we demonstrated the necessity of numerical methods for inference.
We explained LA and MCMC, which form the basis of modern approximate inference methods for Bayesian GLMs.\\

We examined regularized Bayesian models in an applied example under challenging (synthetic) data conditions.
We found that regularization improved predictive performance and reduced the number of covariates falsely declared as informative, particularly in logistic regression.
Comparing MCMC and LA revealed that LA can yield more precise estimates than MCMC despite lower computational speed.
However, this could be mitigated by the specific implementation used in the experiment.
As these examples are meant to be illustrative, we caution against overgeneralizing and note that more efficient regularization and inference tools are readily available.\\

Some limitations of the described methods have been addressed above, such as the need for more complex prior distributions for real variable selection in \Cref{sec:lm-regularization}.
For scenarios that require more flexibility, the Bayesian framework can be extended in plenty of ways.
For example, 
hierarchical (multilevel) GLMs introduce group-specific random effects and can be used for longitudinal data \citep{gelman_weakly_2008}, and structured additive regression extends Bayesian GLMs to work with nonlinear effects \citep{fahrmeir_bayesian_2010}.
% Although this is mathematically and computationally complex, the concept of regarding an already familiar frequentist concept from a Bayesian perspective is much the same as for the relatively simple case of GLMs.
Nevertheless, uncertainty quantification with Bayesian models sill relies on parametric distributional assumptions and can be sensitive to prior misspecification \citep{piironen_comparison_2017}. In contrast, methods like conformal prediction can be applied more generally while guaranteeing finite-sample and  distribution-free coverage of prediction intervals \citep[see e.g.][]{angelopoulos_gentle_2022}.