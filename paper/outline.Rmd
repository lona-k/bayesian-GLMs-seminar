---
title: "Outline: Bayesian (Generalized) Linear Models"
author: "Lona Koers"
output: pdf_document
---

0. Abstract

1. Introduction

    - Motivation of bayesian GLMs
    - Current research and related work
    - Structure of the paper

2. Bayesian Linear Regression

    2.1 Model definition
      - Regular linear model
      - Bayesian linear model

    2.2 Prior choice
      - Uninformative priors (for $\beta$ and $\sigma^2$ or just for $\sigma^2$)
      - Prior distributions for regularization
          - Motivation of regularization
          - Ridge regularization $\iff$ Gaussian prior
          - Focus: Lasso regularization $\iff$ Laplace prior (and other methodes for real variable selection)
      - Other prior distributions and use-cases (i.e. heavy-tailed priors)
    
    2.3 Bayesian inference with closed form priors
      - Posterior and marginal (parameter) distribution
      - Posterior predictive distribution

3. Bayesian Generalized Linear Regression

    3.1 Extending linear regression: Bayesian GLMs

    3.2 (Binary) Logistic regression
      - Model definition
      - Parameter priors

    3.3. Inference methods
      - Laplace approximation
      - MCMC and Hamilton Monte Carlo
      - Predictive posterior estimation

4. Simulation Study

    4.1. Linear Regression (= Regression): prior choice for (Lasso) regularization

    4.2. Logistic Regression (= Classification) 
      <!-- - *(maybe on real data?)* synthetic data (easy 2-dim binary classification where we can draw a line through? maybe effect on the decision boundary with unbalanced classes is interesting?) -->
      <!-- - fit model -->
      <!-- - visualize prior, posterior, predictive posterior, posterior decision boundary -->

6. Conclusion and Outlook

    - When would the use of Bayesian regression be preferred over regular regression?
    - Alternatives for more complex problems: Hierarchical GLMs and GLMMs, Bayesian GAMs

